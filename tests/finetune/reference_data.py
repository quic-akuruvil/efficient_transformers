# -----------------------------------------------------------------------------
#
# Copyright (c) Qualcomm Technologies, Inc. and/or its subsidiaries.
# SPDX-License-Identifier: BSD-3-Clause
#
# -----------------------------------------------------------------------------

"""Reference data for the finetune tests."""

# A dictionary to hold all reference data for all test sets.
REFERENCE_DATA = {
    # Scenario 1: Single-device llama 3.2-1B training on Alpaca dataset.
    "llama_config_alpaca_single_device": {
        "description": "Baseline for Llama on Alpaca single-device",
        "train_step_losses": [
            1.5112206935882568,
            1.2211230993270874,
            1.9942185878753662,
            2.093623161315918,
            0.918222188949585,
            1.2096843719482422,
            0.36385059356689453,
            1.6222058534622192,
            0.8265190124511719,
            0.7740323543548584,
            1.73989999294281,
            2.1174354553222656,
            2.0626680850982666,
            0.8269345164299011,
            0.8087047338485718,
            1.762345552444458,
            1.682948350906372,
            1.353007197380066,
            2.0653581619262695,
            3.155752182006836,
        ],
        "eval_step_losses": [
            1.4651821851730347,
            0.2893582880496979,
            1.0634244680404663,
            1.6548362970352173,
            1.3954527378082275,
            3.40647029876709,
            1.0366579294204712,
            1.8700106143951416,
            3.7695555686950684,
            0.741568922996521,
        ],
        "train_step_metrics": [
            4.532259941101074,
            3.390994071960449,
            7.34645938873291,
            8.114261627197266,
            2.504833221435547,
            3.352426290512085,
            1.438859224319458,
            5.064249038696289,
            2.2853496074676514,
            2.1684927940368652,
            5.696773529052734,
            8.309799194335938,
            7.86693000793457,
            2.286299467086792,
            2.2449982166290283,
            5.82608699798584,
            5.381398677825928,
            3.86904239654541,
            7.888120651245117,
            23.470684051513672,
        ],
        "eval_step_metrics": [  # steps 0-9
            4.32833194732666,
            1.3355700969696045,
            2.8962721824645996,
            5.2322235107421875,
            4.036801815032959,
            30.158601760864258,
            2.819777488708496,
            6.488365173339844,
            43.36079025268555,
            2.099226474761963,
        ],
    },
    # Scenario 2: Single-device llama 3.2-1B training on GSM8k dataset.
    "llama_config_gsm8k_single_device": {
        "description": "Baseline for Llama on GSM8k single-device",
        "train_step_losses": [
            2.250276803970337,
            2.3231687545776367,
            1.9379945993423462,
            1.5981022119522095,
            1.9855612516403198,
            1.4584788084030151,
            1.896289587020874,
            1.2166330814361572,
            1.647794485092163,
            1.5384052991867065,
            1.4012668132781982,
            1.5305882692337036,
            1.6876310110092163,
            1.3843384981155396,
            1.797397494316101,
            1.405611276626587,
            1.6457229852676392,
            1.2822402715682983,
            0.8453481793403625,
            1.577443242073059,
        ],
        "eval_step_losses": [
            1.8507282733917236,
            1.8689926862716675,
            1.216104507446289,
            2.208395004272461,
            1.4272055625915527,
            1.3521459102630615,
            1.3390949964523315,
            1.4000688791275024,
            1.4072850942611694,
            1.374159812927246,
        ],
        "train_step_metrics": [
            9.490362167358398,
            10.207969665527344,
            6.944809913635254,
            4.943641662597656,
            7.283133506774902,
            4.299414157867432,
            6.6611328125,
            3.375802516937256,
            5.1955084800720215,
            4.6571574211120605,
            4.060340404510498,
            4.620894432067871,
            5.4066572189331055,
            3.992183208465576,
            6.033923625946045,
            4.078018665313721,
            5.184757232666016,
            3.604706048965454,
            2.3287885189056396,
            4.842558860778809,
        ],
        "eval_step_metrics": [  # steps 0-9
            6.364452838897705,
            6.48176383972168,
            3.374018669128418,
            9.101097106933594,
            4.167038440704346,
            3.8657114505767822,
            3.8155882358551025,
            4.055479526519775,
            4.084850311279297,
            3.951754093170166,
        ],
    },
    # Scenario 3: Single-device Bert training on IMDB dataset.
    "bert_config_imdb_single_device": {
        "description": "Baseline for BERT on IMDB single-device",
        "train_step_losses": [
            0.390625,
            0.51220703125,
            0.9208984375,
            0.4052734375,
            1.1640625,
            0.6533203125,
            0.5087890625,
            0.76171875,
            0.63525390625,
            0.50146484375,
            0.5439453125,
            0.947265625,
            0.89013671875,
            0.80419921875,
            0.6533203125,
            0.4580078125,
            0.92041015625,
            0.7412109375,
            0.7197265625,
            0.62158203125,
        ],
        "eval_step_losses": [
            0.55126953125,
            0.7421875,
            0.86572265625,
            0.64501953125,
            0.65234375,
            0.60302734375,
            0.638671875,
            0.8232421875,
            0.6611328125,
            0.6240234375,
        ],
        "train_step_metrics": [
            1.0,
            1.0,
            0.5,
            0.5,
            0.5,
            0.5,
            0.5,
            0.5,
            0.625,
            0.625,
            0.625,
            0.5999755859375,
            0.58331298828125,
            0.5714111328125,
            0.5714111328125,
            0.5714111328125,
            0.5625,
            0.5555419921875,
            0.5054931640625,
            0.5101318359375,
        ],
        "eval_step_metrics": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0],
    },
    # Scenario 4: Distributed Bert training  (world_size=2)
    "bert_config_imdb_distributed_ws2": {
        "description": "Baseline for distributed training with 2 devices",
        "world_size": 2,
        "rank_data": {
            0: {  # Data for Rank 0
                "train_step_losses": [],
                "eval_step_losses": [],
                "train_step_metrics": [],
                "eval_step_metrics": [],
            },
            1: {  # Data for Rank 1
                "train_step_losses": [],
                "eval_step_losses": [],
                "train_step_metrics": [],
                "eval_step_metrics": [],
            },
        },
    },
}
