# A dictionary to hold all reference data for all test sets.
REFERENCE_DATA = {
    # Scenario 1: Single-device llama training on Alpaca dataset.
    "llama_config_alpaca_single_device": {
        "description": "Baseline for Llama on Alpaca single-device",
        "train_step_losses": [
            1.5112206935882568,
            1.2211230993270874,
            1.9942185878753662,
            2.093623161315918,
            0.918222188949585,
            1.2096843719482422,
            0.36385059356689453,
            1.6222058534622192,
            0.8265190124511719,
            0.7740323543548584,
            1.73989999294281,
            2.1174354553222656,
            2.0626680850982666,
            0.8269345164299011,
            0.8087047338485718,
            1.762345552444458,
            1.682948350906372,
            1.353007197380066,
            2.0653581619262695,
        ],
        "eval_step_losses": [
            1.4651821851730347,
            0.2893582880496979,
            1.0634244680404663,
            1.6548362970352173,
            1.3954527378082275,
            3.40647029876709,
            1.0366579294204712,
            1.8700106143951416,
            3.7695555686950684,
            0.741568922996521,
        ],
        "train_step_metrics": [
            4.532259941101074,
            3.390994071960449,
            7.34645938873291,
            8.114261627197266,
            2.504833221435547,
            3.352426290512085,
            1.438859224319458,
            5.064249038696289,
            2.2853496074676514,
            2.1684927940368652,
            5.696773529052734,
            8.309799194335938,
            7.86693000793457,
            2.286299467086792,
            2.2449982166290283,
            5.82608699798584,
            5.381398677825928,
            3.86904239654541,
            7.888120651245117,
        ],
        "eval_step_metrics": [  # steps 0-9
            4.32833194732666,
            1.3355700969696045,
            2.8962721824645996,
            5.2322235107421875,
            4.036801815032959,
            30.158601760864258,
            2.819777488708496,
            6.488365173339844,
            43.36079025268555,
            2.099226474761963,
        ],
    },
    "llama_config_gsm8k_single_device": {
        "description": "Baseline for Llama on GSM8k single-device",
        "train_step_losses": [
            2.250276803970337,
            2.3231687545776367,
            1.9379945993423462,
            1.5981022119522095,
            1.9855612516403198,
            1.4584788084030151,
            1.896289587020874,
            1.2166330814361572,
            1.647794485092163,
            1.5384052991867065,
            1.4012668132781982,
            1.5305882692337036,
            1.6876310110092163,
            1.3843384981155396,
            1.797397494316101,
            1.405611276626587,
            1.6457229852676392,
            1.2822402715682983,
            0.8453481793403625,
        ],
        "eval_step_losses": [
            1.8507282733917236,
            1.8689926862716675,
            1.216104507446289,
            2.208395004272461,
            1.4272055625915527,
            1.3521459102630615,
            1.3390949964523315,
            1.4000688791275024,
            1.4072850942611694,
            1.374159812927246,
        ],
        "train_step_metrics": [  # steps 0-9
            9.490362167358398,
            10.207969665527344,
            6.944809913635254,
            4.943641662597656,
            7.283133506774902,
            4.299414157867432,
            6.6611328125,
            3.375802516937256,
            5.1955084800720215,
            4.6571574211120605,
            4.060340404510498,
            4.620894432067871,
            5.4066572189331055,
            3.992183208465576,
            6.033923625946045,
            4.078018665313721,
            5.184757232666016,
            3.604706048965454,
            2.3287885189056396,
        ],
        "eval_step_metrics": [  # steps 0-2
            6.364452838897705,
            6.48176383972168,
            3.374018669128418,
            9.101097106933594,
            4.167038440704346,
            3.8657114505767822,
            3.8155882358551025,
            4.055479526519775,
            4.084850311279297,
            3.951754093170166,
        ],
    },
    # Scenario 3: Single-device Bert training on IMDB dataset.
    "bert_config_imdb_single_device": {
        "description": "Baseline for BERT on IMDB single-device",
        "train_step_losses": [
            5,  # steps 0-9
            0.39,
            0.37,
            0.35,
            0.33,
            0.31,
            0.29,
            0.27,
            0.25,
            0.23,
            0.21,  # steps 10-19
        ],
        "eval_step_losses": [0.70, 0.50, 0.30],
        "train_step_metrics": [
            0.10,
            0.15,
            0.20,
            0.25,
            0.30,
            0.35,
            0.40,
            0.45,
            0.50,
            0.55,
            0.60,
            0.65,
            0.70,
            0.75,
            0.80,
            0.82,
            0.84,
            0.86,
            0.88,
            0.90,
        ],
        "eval_step_metrics": [0.25, 0.45, 0.80],
    },
    # Scenario 4: Distributed training (world_size=2)
    "bert_config_imdb_distributed_ws2": {
        "description": "Baseline for distributed training with 2 devices",
        "world_size": 2,
        "rank_data": {
            0: {  # Data for Rank 0
                "train_step_losses": [
                    0.91,
                    0.86,
                    0.81,
                    0.76,
                    0.71,
                    0.66,
                    0.61,
                    0.56,
                    0.51,
                    0.46,
                    0.41,
                    0.39,
                    0.37,
                    0.35,
                    0.33,
                    0.31,
                    0.29,
                    0.27,
                    0.25,
                    0.23,
                ],
                "eval_step_losses": [0.72, 0.52, 0.32],
                "train_step_metrics": [
                    0.09,
                    0.14,
                    0.19,
                    0.24,
                    0.29,
                    0.34,
                    0.39,
                    0.44,
                    0.49,
                    0.54,
                    0.59,
                    0.64,
                    0.69,
                    0.74,
                    0.79,
                    0.81,
                    0.83,
                    0.85,
                    0.87,
                    0.89,
                ],
                "eval_step_metrics": [0.26, 0.46, 0.81],
            },
            1: {  # Data for Rank 1
                "train_step_losses": [
                    0.92,
                    0.87,
                    0.82,
                    0.77,
                    0.72,
                    0.67,
                    0.62,
                    0.57,
                    0.52,
                    0.47,
                    0.42,
                    0.40,
                    0.38,
                    0.36,
                    0.34,
                    0.32,
                    0.30,
                    0.28,
                    0.26,
                    0.24,
                ],
                "eval_step_losses": [0.73, 0.53, 0.33],
                "train_step_metrics": [
                    0.08,
                    0.13,
                    0.18,
                    0.23,
                    0.28,
                    0.33,
                    0.38,
                    0.43,
                    0.48,
                    0.53,
                    0.58,
                    0.63,
                    0.68,
                    0.73,
                    0.78,
                    0.80,
                    0.82,
                    0.84,
                    0.86,
                    0.88,
                ],
                "eval_step_metrics": [0.27, 0.47, 0.82],
            },
        },
    },
}
